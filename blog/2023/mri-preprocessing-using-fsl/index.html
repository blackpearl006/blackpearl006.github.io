<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <p>This tutorial should help you to work your way throughÂ FSL</p> <p>For this article / tutorial i have used the a MRI image from OASIS dataset which you can access using this linkÂ <a href="https://github.com/blackpearl006/MRI-analysis-using-FSL" rel="external nofollow noopener" target="_blank">ðŸ”—</a></p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/960/1*rlrgg0lC8e1rMNGUdP5G1A.gif"><figcaption>Using 3d slicer visualize the MRIÂ scan</figcaption></figure> <p>Extract information about the MRIÂ image</p> <pre>fslinfo mri_image.nii.gz</pre> <p>the output of the above command gives a lot of information about the MRI image file and not about theÂ subject</p> <p>dim1 128 dim2 256 dim3 256 shows that this is a 128x256x256 matrix <br>the output also mentions that each voxel is 1.25 mm x 1 mm x 1Â mm</p> <p>FSL assumes that the brain is made up of small volumes and this can be visualized below</p> <iframe src="https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fsketchfab.com%2Fmodels%2Fccdcbe54a5ae490e8a4f8073838f7f9a%2Fembed&amp;display_name=Sketchfab&amp;url=https%3A%2F%2Fsketchfab.com%2F3d-models%2Fvoxel-brain-ccdcbe54a5ae490e8a4f8073838f7f9a&amp;image=https%3A%2F%2Fmedia.sketchfab.com%2Fmodels%2Fccdcbe54a5ae490e8a4f8073838f7f9a%2Fthumbnails%2F5f4baf7757474c68a9d1182d4df253bb%2F107f48468f944cd5aa1ba06884f8d302.jpeg&amp;key=a19fcc184b9711e1b4764040d3dc5c07&amp;type=text%2Fhtml&amp;schema=sketchfab" width="640" height="360" frameborder="0" scrolling="no"><a href="https://medium.com/media/cecb9383fa089362a1eb402a40e59aa6/href" rel="external nofollow noopener" target="_blank">https://medium.com/media/cecb9383fa089362a1eb402a40e59aa6/href</a></iframe> <h3>Skull Stripping</h3> <p>we are going remove the skull non tissue part of theÂ brain</p> <pre>bet2 mri_image.nii.gz skull_stripped -f 0.5</pre> <figure><img alt="" src="https://cdn-images-1.medium.com/max/960/1*3AKz1OwMFQiGrhXrg7BQxA.gif"><figcaption>skull stripped MRIÂ image</figcaption></figure> <p>bet2 has a important parameter Fractional Intensity Parameter (f) which is set to a default value of 0.5, smaller values of f give larger brain outline estimates.</p> <blockquote>AssignmentÂ : Try using various different values of F and see whatÂ happens</blockquote> <h3>Field ofÂ view</h3> <p>Not all the part of the MRI image is important, we can discard the lower head and neck part of the MRI image so that we can focus more on the brain, we use a tool roboustfov</p> <pre>robustfov -v -i skull_stripped.nii.gz -r roiimage</pre> <blockquote>Final FOV is: <br>0.000000 128.000000 0.000000 256.000000 85.000000 170.000000 <br>Xmin Xmax Ymin Ymax ZminÂ Zmax</blockquote> <pre>fslinfo roiimage.nii.gz</pre> <blockquote>MRI image is now of the shape 128x256x170</blockquote> <h3>Reorientation</h3> <p>Sometimes the MRI images are not in the standard orientation like they can be flipped, mirroredÂ , then we can run fslreorient2std this is not a registration tool and can perform only 90Â°, 180Â°, 270Â° rotations</p> <pre>fslreorient2std roiimage.nii.gz<br>#to create a new output file with the orienattion of the standard MNI template<br>fslreorient2std roiimage.nii.gz reoriented</pre> <blockquote>1 0 0 0<br>0 1 0 0<br>0 0 1 0<br>0 0 0Â 1</blockquote> <p>the output is a identity matrix, implying that the MRI image in the correct orientation ie,</p> <ul> <li>x axis orient Right-to-Left</li> <li>y axis orient Posterior-to-Anterior</li> <li>z axis orient Inferior-to-Superior</li> </ul> <h3>Brain Segmentation</h3> <p>now we have a skull stripped brain image and we will segment the brain into various parts, normally White matter, Grey Matter &amp; Cerebrospinal fluid (CSF) in case of T1 weighted MRI images, if there are big lesions in the brainÂ , we can classify them into anotherÂ class</p> <p>we use FAST tool to achieve brain and along with segmentation it also corrects the bias in the the MRI images. FAST uses Mori-Tanaka approach to classify the voxel into a class and each voxel can belong to different classes, the probability of it belonging to a class is showed in itâ€™s intensity</p> <blockquote>Assignment: Find out what is Bias in the MRI images, Is it Spatially invariant orÂ not.</blockquote> <p>HINTÂ : check -b option inÂ fast</p> <p>FAST is a iterative tool and there is a trade off between number of iterations (time taken) and the accuracy of the segmentation.</p> <pre>fast -o fast_out -b -B -t 1 --iter=10 -v roiimage.nii.gz </pre> <p>outputÂ :<br>.<br>â”œâ”€â”€ fast_out_bias.nii.gz <br>â”œâ”€â”€ fast_out_mixeltype.nii.gz<br>â”œâ”€â”€ fast_out_pve_0.nii.gz<br>â”œâ”€â”€ fast_out_pve_1.nii.gz<br>â”œâ”€â”€ fast_out_pve_2.nii.gz<br>â”œâ”€â”€ fast_out_pveseg.nii.gz<br>â”œâ”€â”€ fast_out_restore.nii.gz<br>â”œâ”€â”€ fast_out_seg.nii.gz<br>â”œâ”€â”€ mri_image.nii.gz<br>â”œâ”€â”€ reoriented.nii.gz<br>â”œâ”€â”€ roiimage.nii.gz<br>â””â”€â”€ skull_stripped.nii.gz</p> <p><strong>Partial volume maps </strong>(pve)Â , for each class, where each voxel contains a value in the range 0â€“1 that represents the proportion of that classâ€™s tissue present in thatÂ voxel.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/960/1*ku-jqefVQoaROlf2NUAmTw.gif"><figcaption>partial volume maps for class0 (CNF), class1 (Grey matter) and class2 (WhiteÂ Matter)</figcaption></figure> <p><strong>Restored input</strong> is the estimated restored input image after correction for biasÂ field.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/960/1*EDF1GFsQk4YuipO2XUl3WA.gif"><figcaption>this is the bias corrected outputÂ image</figcaption></figure> <p><strong>Bias field</strong> is the estimated biasÂ field.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*9i9VQjHqgn1DkeUnQbuwXA.gif"><figcaption>bias is not spatially invariant</figcaption></figure> <p>Fast Segmented imagesÂ ,, has all the classes in a single MRIÂ image</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/960/1*bVVmVQLD4FsKNoT-z95clA.gif"><figcaption>Segmented MRIÂ image</figcaption></figure> <p>The brain segmentation is very useful in Volumetric caluclations, which we wont look intoÂ now,</p> <h3>Template registration</h3> <p>We want the same cartesian / voxel co-ordinates to point us at the same anatomical structure ie, align the MRIÂ image.</p> <p><strong>Why do we do soÂ ?? Isnâ€™t this tampering with the MRIÂ data</strong></p> <ol> <li>For combining / comparing across various groups ofÂ people</li> <li>Quantify structural changes</li> <li>correcting motion artifacts in fMRIÂ study</li> </ol> <figure><img alt="" src="https://cdn-images-1.medium.com/max/935/1*yo4JHgCOHPPmZoIw9k-tOA.png"><figcaption>same location points to different anatomical structures, image only for illustration</figcaption></figure> <figure><img alt="" src="https://cdn-images-1.medium.com/max/650/1*A7Yy1sEbaxhr2mtVfW3X3A.png"><figcaption>voxel location = anatomical location</figcaption></figure> <p>Types of transformations</p> <ol> <li>Rigid body (6 DOF) used normally within-subject motion<br>3 Rotations, 3 Translations (All the possible motions without changing the shape /Â size)</li> <li>Non-linear (lots of DOF!) has high-quality image and works better with a non-linear template (e.g. MNI152_TI_2mm)<br>Can be specific to the region and match the tempalate</li> <li>Affine (12 DOF) needed as a starting point for non-linear align to affine template, or using lower quality images, or eddy current correction<br>Along with the Rigid Body transformations it has 3 scaling and 3Â skews</li> <li>Global scaling (7 DOF) within-subject but with global scaling (equal in x,y,z) corrects for scanner scaling drift in longitudinal studies</li> </ol> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*g_ltmmMR93RH_qqZTC6DIg.png"></figure> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*fOoxPCRbn0xARFYq1quYxA.png"><figcaption>LeftÂ : Bias corrected, skull stripped MRI input image Right: MNI158Â template</figcaption></figure> <h4>Linear transformation</h4> <pre>flirt -in fast_out_restore.nii.gz -ref /Users/ninad/fsl/data/standard/MNI152_T1_2mm.nii.gz -dof 12 -omat MRI_to_MNI.mat -out affine_trans</pre> <p>the above command does the affine transformation (12 DOF) to registers the MRI image to MNI158 standard 2mm template and furture help in the non linear transformation. -in the input MRI image path, -ref reference template (we used MNI 2mm template) -dof specifies DOF and i wanted Affine transformation so set it to 12, -omat outputs a 4x4 matrix in aÂ .mat file with the affine transformation values, -out outputs the MRI image after registering to the reference image</p> <pre>cat MRI_to_MNI.mat</pre> <blockquote>| 0.04992739769 -0.009461175045 1.376357676 -31.28157938 |<br>| -1.610147028 -0.1469847473 0.03976417704 252.6235512 |<br>| 0.182484106 -1.599149772 0.1794447228 206.7580262 |<br>| 0 0 0 1Â |</blockquote> <figure><img alt="" src="https://cdn-images-1.medium.com/max/960/1*65HTU0VJoOVtOvuny1XhoQ.gif"><figcaption>MNI158 registered template</figcaption></figure> <p>The affine transformation can result in various changes like change in axisÂ , for the visualization you can useÂ the</p> <pre>fslreorient2std affine_trans.nii.gz reoriented_affine_tranform</pre> <p>There are many cost functions available in FLIRT, within-modality functions Least Squares and Normalised Correlation, as well as the between-modality functions Correlation Ratio (the default), Mutual Information and Normalised Mutual Information.<br>within-modality means the reference and the input MRI image should be of sameÂ type</p> <h4>Non linear Transformation</h4> <ul> <li>Bending energy regularization penalizes deformations that involve bending or warping of the image too much. It encourages smoother and more gradual deformations.</li> <li>This regularization is typically used when you want to avoid sharp and unrealistic deformations in the transformation field. It is especially useful when the deformation should be smooth and gradual, such as in medical image registrationFnirt is a command line program that is run by typing fnirt followed by some set of parameters. The minimum you need to typeÂ is</li> </ul> <pre>fnirt --in=affine_trans.nii.gz --ref=/Users/ninad/fsl/data/standard/MNI152_T1_2mm  -v</pre> <p>but it is not very likely it will do you any good. Fnirt has a large set of parameters that determine what is done, and how it is done. Without a knowledge of these parameters you will not get the best results that youÂ can.</p> <p>Efficiently usingÂ FNIRT</p> <pre>fnirt --in=roiimage.nii.gz --ref=/Users/ninad/fsl/data/standard/MNI152_T1_2mm.nii.gz --aff=MRI_to_MNI.mat --refmask=/Users/ninad/fsl/data/standard/MNI152_T1_2mm_brain_mask_dil.nii --config=/Users/ninad/fsl/etc/flirtsch/T1_2_MNI152_2mm.cnf --cout=fnirt_coef_warp --iout=fnirt_warped --fout=fnirt_warp --jout=fnirt_jacobian --refout=fnirt_ref_intensity --intout=fnirt_intensity_modulation -v --logout=fnirt_log</pre> <figure><img alt="" src="https://cdn-images-1.medium.com/max/960/1*kT8xzOOJfPkrCtqHasKSSA.gif"><figcaption>FNIRT output</figcaption></figure> <p>Is this what we were looking forÂ ??<br>Comment below what went wrongâ€¦..? ðŸ¤”</p> <blockquote>AssignmentÂ : check out the config file located at <em>fsl/etc/flirtsch/T1_2_MNI152_2mm.cnf</em> and compare it with the options defined for the fnirt tool usingâ€Šâ€”â€Šhelp option<br>Future workÂ : Try to run fsl using R programming language using any fsl wrapper <a href="https://rdrr.io/github/neuroconductor-devel-releases/fslr/man/download_fsl.html" rel="external nofollow noopener" target="_blank">packages</a> <br>NotesÂ : always use -v (verbose) option in your commands to know whatâ€™s happening</blockquote> <p>ReferencesÂ : <a href="https://youtu.be/2zcfYgdxhKM?si=cZxzpJqOPKjCp7QB" rel="external nofollow noopener" target="_blank">FSL Course</a>, <a href="https://ggooo.wordpress.com/2014/07/31/inverse-transformation-using-flirt-2/" rel="external nofollow noopener" target="_blank">Random code</a>, <a href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FNIRT/UserGuide" rel="external nofollow noopener" target="_blank">FSL userÂ guide</a></p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=383a67e7185" width="1" height="1" alt=""></p> </body></html>