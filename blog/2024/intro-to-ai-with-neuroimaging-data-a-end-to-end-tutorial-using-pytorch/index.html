<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*FTycrusmzsEmAONYWL_c5Q.png"><figcaption>Neurolight Logo; AI generated</figcaption></figure> <p>This is a beginner-friendly guide to using artificial intelligence with neuroimaging data. This tutorial takes you step-by-step through the entire process, starting from loading and understanding MRI data, to building and training deep learning models in PyTorch. Along the way, you’ll learn essential AI and machine learning concepts, see how to set up a dataset for training, and explore real-world tasks like classifying brain images. With clear explanations and practical examples, this tutorial is designed to make complex ideas easy to understand, helping you get hands-on experience with AI in healthcare applications and giving you the skills to work on exciting neuroimaging projects from start to finish.</p> <h3>File Structure and Labels</h3> <p>You must be able to uniquely match your file with it’s corresponding entry in the metadata. For this purpose always encode a unique subject id usually provided by the dataset as a part of the filename. For the purpose of this project I have used preprocessed <a href="https://www.humanconnectome.org/study/hcp-young-adult/data-releases" rel="external nofollow noopener" target="_blank">HCP dataset</a>. The NifTi images are named as Sub-100004.nii.gz &amp; Sub-100206.nii.gz etc. All the files are located in a single folder without any sub-directories. The metadata file is Metadata.csv file, where you can map the filename with unique Subject column.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*gQIpRiMsCM4fobRrgqvj4w.png"><figcaption>Sample metadata.csv</figcaption></figure> <h4>Importing necessary libraries</h4> <pre>import os<br>import logging<br>import torch<br>import torch.nn as nn<br>import torch.nn.functional as F<br>from sklearn.model_selection import train_test_split<br>import numpy as np<br>import logging<br>import datetime<br>import nibabel as nib<br>import pandas as pd<br>import seaborn as sns<br>from sklearn.metrics import confusion_matrix, accuracy_score, recall_score<br>import matplotlib.pyplot as plt<br>from sklearn.model_selection import KFold<br>from torch.utils.data import DataLoader, Subset, random_split, Dataset<br>from torch.utils.data import *</pre> <h4>Hyper parameters</h4> <p>Initialing all the required hyper-parameters <strong>forefront</strong>. (Important !!, As you get experience, you’ll understand why !!, For now, Take my word)</p> <pre>VAL_RATIO = 0.2<br>TEST_RATIO = 0.2<br>TRAIN_RATIO = 1 - VAL_RATIO - TEST_RATIO<br>DATA_PARALELL = True<br>DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")<br>DATASET = 'HCP'<br>PHASE = 'TRAIN'<br>K_FOLDS = 5<br><br>TASK = 'classification'<br>ROOT_DIR = 'path/to/dataset/HCP'<br>LABEL_DIR='path/to/metadata/metadata.csv'<br>LOG_DIR = 'path/to/scripts/logs'<br>timestamp = datetime.datetime.now().strftime('%d_%m_%Y_%H_%M_%S')<br>RESULT_DIR = f'path/to/scripts/results/run_{timestamp}'<br>os.makedirs(RESULT_DIR,exist_ok=True)<br>TEST_BATCH_SIZE = 2<br><br>BATCH_SIZE=16<br>LEARNING_RATE=0.0001<br>NUM_EPOCHS = 10<br>EARLY_STOPPING_PATIENCE = 5<br><br>NP_SEED = 42<br>TORCH_SEED = 36</pre> <h4>Setting up the Seed</h4> <pre>np.random.seed(NP_SEED)<br>torch.manual_seed(TORCH_SEED)</pre> <h4><strong>Setting up logger</strong></h4> <pre>def setup_logger(logs_dir=LOG_DIR,dataset=None,phase=None):<br>    os.makedirs(logs_dir, exist_ok=True)<br>    logger = logging.getLogger('RunLogger')<br>    logger.setLevel(logging.INFO)<br><br>    if not logger.hasHandlers():<br>        timestamp = datetime.datetime.now().strftime('%d_%m_%Y_%H_%M_%S')<br>        file_handler = logging.FileHandler(os.path.join(logs_dir, f'{phase}_{dataset}_{timestamp}.log'))<br>        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')<br>        file_handler.setFormatter(formatter)<br>        logger.addHandler(file_handler)<br>    <br>    return logger<br><br>LOGGER = setup_logger(logs_dir=LOG_DIR,phase=PHASE,dataset=DATASET)</pre> <h3>Dataset Class</h3> <pre>class Fieldmapdata(Dataset):<br>    """<br>    Dataset class for loading neuroimaging data and associated labels for classification or regression tasks.<br><br>    Attributes:<br>        root_dir (str): Path to the directory containing image data files (.nii or .nii.gz).<br>        label_dir (str): Path to the CSV file containing labels for each subject.<br>        task (str): Specifies the task type: classification (Gender) or regression (Age).<br>    """<br>    def __init__(self, root_dir, label_dir, task='classification'):<br>        self.labels_df = self.load_labels(label_dir) #load the labels<br>        self.samples = self.make_dataset(root_dir, task=task) #assign the labels to each file in the root_dir<br><br>    def __len__(self):<br>        return len(self.samples)<br><br>    def __getitem__(self, idx):<br>        img_path, label = self.samples[idx]<br>        nifti_data = nib.load(img_path)<br>        data = nifti_data.get_fdata()<br>        image_tensor = torch.tensor(data, dtype=torch.float32).unsqueeze(0) #unsqueeze to add channel dimension<br>        label_tensor = torch.tensor(label, dtype=torch.float32).unsqueeze(0)<br>        return image_tensor, label_tensor<br>       <br>    def make_dataset(self, root_dir, task = None):<br>        samples = []<br>        labels_df = self.labels_df<br>        for root, _, fnames in os.walk(root_dir):<br>            for fname in fnames:<br>                if fname.endswith(".nii.gz") or fname.endswith(".nii"):<br>                    path = os.path.join(root, fname)<br>                    id_ = self.extract_id_from_filename(fname)<br>                    try:<br>                        if task == 'regression': <br>                            label = labels_df[labels_df['Subject'] == id_]['Age'].iloc[0] <br>                        if task == 'classification': <br>                            label = labels_df[labels_df['Subject'] == id_]['Gender'].iloc[0]<br>                        samples.append((path, label))<br>                    except:<br>                        continue<br>        return samples<br>    <br>    def extract_id_from_filename(self, fname):<br>        '''match the filename to key to query in the labels dictionary'''<br>        fname = fname.replace("sub-","")<br>        if fname.endswith("_ad.nii.gz"):<br>            id_ = fname.replace("_ad.nii.gz", "")<br>        elif fname.endswith("_rd.nii.gz"):<br>            id_ = fname.replace("_rd.nii.gz", "")<br>        elif fname.endswith("_adc.nii.gz"):<br>            id_ = fname.replace("_adc.nii.gz", "")<br>        elif fname.endswith("_fa.nii.gz"):<br>            id_ = fname.replace("_fa.nii.gz", "")<br>        elif fname.endswith(".nii.gz"):<br>            id_ = fname.replace(".nii.gz", "")<br>        return id_<br><br>    def load_labels(self, label_path):<br>        '''tip: use astype(required datatype)'''<br>        df = pd.read_csv(label_path)<br>        df_filtered = df[['Subject', 'Gender', 'Age']].copy()<br>        df_filtered['Gender'] = df_filtered['Gender'].map({'M': 0, 'F': 1}).astype(int)<br>        df_filtered['Age'] = df_filtered['Age'].apply(lambda x: (int(x.split('-')[0]) + int(x.split('-')[1])) // 2 if '-' in x else int(x[:-1])).astype(float)<br>        # In HCP-Y age is a bin of 4 years, here i can assigning the average value of the bin range to each subject<br>        df_filtered['Subject'] = df_filtered['Subject'].astype(str)<br>        return df_filtered</pre> <blockquote>The Fieldmapsclass is a custom PyTorch dataset designed to load neuroimaging data for classification or regression tasks, handling both image files and associated labels. It expects a directory of images (NIfTI files) and a csv file containing labels for each subject. When instantiated, the class initializes by loading the labels from the csv and preparing a list of samples, where each sample pairs an image path with its corresponding label. This process, managed by the make_dataset function, iterates through the directory of images, retrieves the subject ID from each filename using the extract_id_from_filename method, and matches it to the appropriate label from the csv file. The labels are processed in load_labels, where ‘<strong>Gender</strong>’ is encoded numerically (0 for male and 1 for female), and ‘<strong>Age</strong>’ is computed as an average for any age bins specified in ranges.</blockquote> <blockquote>The __getitem__method loads an image and its corresponding label, converting the image data to a PyTorch tensor with a channel dimension added for compatibility with neural networks. This method allows each sample to be easily accessed by an index, making the class compatible with PyTorch’s DataLoader. This dataset structure provides flexibility to handle both classification (e.g., gender prediction) and regression tasks (e.g., age prediction) using the same base code, simplifying loading and preparing neuroimaging data for deep learning applications.</blockquote> <h4>Create the dataset and split into training and testing</h4> <pre>dataset = Fieldmapdata(root_dir=ROOT_DIR,label_dir=LABEL_DIR,task=TASK)<br>train_dataset, val_dataset, test_dataset = random_split(dataset, [TRAIN_RATIO, VAL_RATIO, TEST_RATIO])</pre> <h4><strong>Dataloader</strong></h4> <pre>train_dl = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)<br>val_dl = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)<br>test_dl = DataLoader(test_dataset, batch_size=TEST_BATCH_SIZE, shuffle=False)</pre> <h4><strong>Comparing the shape of image at each stage</strong></h4> <pre>RANDOM_IMAGE_PATH = 'path/to/dataset/sub-100610.nii.gz'<br>raw_image = nib.load(RANDOM_IMAGE_PATH).get_fdata()<br>train_image = train_dataset.__getitem__(1)[0]<br>train_batch = next(iter(train_dl))<br><br>print('Raw image shape',raw_image.shape,'\n' 'Train image shape', train_image.shape,'\n' 'Batch shape',train_batch[0].shape)</pre> <blockquote>Raw image shape → (91, 109, 91) <br>Train image shape → torch.Size([1, 91, 109, 91]) <br>Batch shape → torch.Size([16, 1, 91, 109, 91])</blockquote> <h4>Stratify the labels for classification</h4> <pre>def stratified_split_classification(dataset, test_size):<br>    labels = [dataset[i][-1] for i in range(len(dataset))]  # Assuming label is the last element<br>    # cannot access sample variable for all instances, will thorw AttributeError: 'Subset' object has no attribute 'samples'<br>    train_indices, test_indices = train_test_split(<br>        range(dataset.__len__()), test_size=test_size, stratify=labels<br>    )<br>    train_ds = Subset(dataset, train_indices)<br>    test_ds = Subset(dataset, test_indices)<br>    return train_ds, test_ds<br><br>def splitting_data(dataset, TEST_RATIO: float, stratify: bool=False):<br>    if stratify:<br>        train_ds, test_ds = stratified_split_classification(dataset, TEST_RATIO)<br>    else:<br>        train_ds, test_ds = random_split(dataset, [1-TEST_RATIO, TEST_RATIO])<br>    return train_ds, test_ds</pre> <pre>train_and_val_ds, test_ds = stratified_split_classification(dataset, test_size=TEST_RATIO)<br>train_ds, val_ds = stratified_split_classification(train_and_val_ds, test_size=VAL_RATIO)<br>LOGGER.info('Data split completed !!')</pre> <pre>dataset_labels = []<br>for ds in [train_ds, val_ds, test_ds]:<br>    labels = []<br>    for i, j in ds:<br>        labels.append(j)<br>    dataset_labels.append(labels)<br>    <br>for num, phase in enumerate(['Train', 'Val', 'Test']):<br>    Total_subjects = len(dataset_labels[num]), <br>    males_count = len(dataset_labels[num]) - sum(dataset_labels[num])<br>    females_count = sum(dataset_labels[num]), <br>    ratio = (len(dataset_labels[num]) - sum(dataset_labels[num])) / sum(dataset_labels[num])<br>    print(f'Phase {phase}, total: {Total_subjects[0]}, ratio: {ratio}')</pre> <blockquote>Phase Train, total: 542, ratio: tensor([0.8007])<br>Phase Val, total: 136, ratio: tensor([0.7895])<br>Phase Test, total: 170, ratio: tensor([0.7895])</blockquote> <blockquote>The code defines functions to split a dataset into training, validation, and test sets, with the option to stratify the splits based on class labels. stratified_split_classification performs a stratified split, ensuring that the distribution of labels in the train and test sets matches the original dataset’s distribution, which is particularly useful in classification tasks to prevent class imbalance. The splitting_data function uses this stratified approach if stratify=True; otherwise, it performs a random split.</blockquote> <blockquote>After splitting, the code counts and logs the total number of subjects, along with the counts and ratio of males to females, for each phase (Train, Val, Test). Stratification is crucial when there is class imbalance, as it ensures that each split has a similar proportion of classes, helping to prevent biased model training and evaluation results.</blockquote> <pre>train_dl = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)<br>val_dl = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)<br>test_dl = DataLoader(test_dataset, batch_size=TEST_BATCH_SIZE, shuffle=False)</pre> <h3><strong>Model</strong></h3> <pre>'''copied from https://github.com/ha-ha-ha-han/UKBiobank_deep_pretrain/blob/master/dp_model/model_files/sfcn.py'''<br>'''This code is hardcoded for a specific input shape: ie. [batch_size, 1, 160, 192, 160]'''<br><br>class SFCN(nn.Module):<br>    def __init__(self, channel_number=[32, 64, 128, 256, 256, 64], output_dim=1, dropout=True): #default output_dim changed from 40 to 1<br>        super(SFCN, self).__init__()<br>        n_layer = len(channel_number)<br>        self.feature_extractor = nn.Sequential()<br>        for i in range(n_layer):<br>            if i == 0:<br>                in_channel = 1<br>            else:<br>                in_channel = channel_number[i-1]<br>            out_channel = channel_number[i]<br>            if i &lt; n_layer-1:<br>                self.feature_extractor.add_module('conv_%d' % i,<br>                                                  self.conv_layer(in_channel,<br>                                                                  out_channel,<br>                                                                  maxpool=True,<br>                                                                  kernel_size=3,<br>                                                                  padding=1))<br>            else:<br>                self.feature_extractor.add_module('conv_%d' % i,<br>                                                  self.conv_layer(in_channel,<br>                                                                  out_channel,<br>                                                                  maxpool=False,<br>                                                                  kernel_size=1,<br>                                                                  padding=0))<br>        self.classifier = nn.Sequential()<br>        ############################## Hard coded ####################################### <br>        #avg_shape = [5, 6, 5] <br>        #self.classifier.add_module('average_pool', nn.AvgPool3d(avg_shape))<br>        ############################## Hard coded ####################################### <br><br>        ############################## Change ####################################### <br>        self.classifier.add_module('average_pool', nn.AdaptiveAvgPool3d(1))<br>        ############################## Change ####################################### <br><br>        if dropout is True:<br>            self.classifier.add_module('dropout', nn.Dropout(0.5))<br>        i = n_layer<br>        in_channel = channel_number[-1]<br>        out_channel = output_dim<br>        self.classifier.add_module('conv_%d' % i,<br>                                   nn.Conv3d(in_channel, out_channel, padding=0, kernel_size=1))<br><br>    @staticmethod<br>    def conv_layer(in_channel, out_channel, maxpool=True, kernel_size=3, padding=0, maxpool_stride=2):<br>        if maxpool is True:<br>            layer = nn.Sequential(<br>                nn.Conv3d(in_channel, out_channel, padding=padding, kernel_size=kernel_size),<br>                nn.BatchNorm3d(out_channel),<br>                nn.MaxPool3d(2, stride=maxpool_stride),<br>                nn.ReLU(),<br>            )<br>        else:<br>            layer = nn.Sequential(<br>                nn.Conv3d(in_channel, out_channel, padding=padding, kernel_size=kernel_size),<br>                nn.BatchNorm3d(out_channel),<br>                nn.ReLU()<br>            )<br>        return layer<br><br>    def forward_original (self, x):<br>        out = list()<br>        x_f = self.feature_extractor(x)<br>        x = self.classifier(x_f)<br>        x = F.log_softmax(x, dim=1)<br>        out.append(x)<br>        return out<br>    <br>    def forward(self, x):<br>        '''Instead of list output datatype i prefer tensor and as we are performing Binary classification / Regression, we will not apply softmax'''<br>        # print('In shape', x.shape)<br>        x_f = self.feature_extractor(x)<br>        # print('After feature extraction module shape', x_f.shape)<br>        x = self.classifier(x_f)<br>        # print('After classification module shape', x.shape)<br>        x = x.view(x.size(0), -1) #flattening<br>        # print('After Flattening shape', x.shape)<br>        return x</pre> <pre>from torchinfo import summary<br>model = SFCN()<br>summary(model=model, input_size=(16,1,91,109,91))</pre> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*Ejcav5KF08FaWOtyx41aQw.png"><figcaption>Detailed view of the SFCN model</figcaption></figure> <h4><strong>Initializing Model, Optimizer &amp; Loss</strong></h4> <pre>model = SFCN().to(DEVICE)<br>optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)<br>criterion = nn.BCEWithLogitsLoss() <br># criterion2 = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(1.28,dtype=torch.float32)) # Total subjects: 899 Number of males : 395, number of females: 504, pos_weight = 1.2759493670886075<br># Females are class 1, ratio of class to class 0 --&gt; 504/395 = 1.27</pre> <h4>Simple Training and Validation loop</h4> <pre>train_losses, val_losses = [], []<br>train_accuracies, val_accuracies = [], []<br><br>for epoch in range(NUM_EPOCHS):<br>    model.train()<br>    train_loss = 0.0<br>    train_total = 0<br>    train_correct = 0<br><br>    for inputs, labels in train_dl:<br>        inputs = inputs.to(DEVICE)<br>        labels = labels.to(DEVICE)<br>        optimizer.zero_grad()<br>        outputs = model(inputs)<br>        tloss = criterion(outputs, labels)<br>        tloss.backward()<br>        optimizer.step()<br>        train_loss += tloss.item() / inputs.size(0)<br>        probability = torch.sigmoid(outputs) # during inference you have to apply sigmoid<br>        predicted = (probability &gt;= 0.5).float()<br>        train_total += labels.size(0)<br>        train_correct += (predicted == labels).sum().item()<br><br>    train_accuracy = 100 * train_correct / train_total<br>    train_accuracies.append(train_accuracy)<br>    train_losses.append(train_loss)<br><br>    model.eval()<br>    val_loss = 0.0<br>    val_total = 0<br>    val_correct = 0<br><br>    with torch.no_grad():<br>        for inputs, labels in val_dl:<br>            inputs = inputs.to(DEVICE)<br>            labels = labels.to(DEVICE)<br>            outputs = model(inputs)<br>            vloss = criterion(outputs, labels)<br>            val_loss += vloss.item() / inputs.size(0)<br>            probability = torch.sigmoid(outputs)<br>            predicted = (probability &gt;= 0.5).float()<br>            val_total += labels.size(0)<br>            val_correct += (predicted == labels).sum().item()<br><br>        val_accuracy = 100 * val_correct / val_total<br>        val_accuracies.append(val_accuracy)<br>        val_losses.append(val_loss)<br><br>        print(f"Epoch [{epoch+1}/{NUM_EPOCHS}]: Train Loss: {train_loss:.4f} Train Accu: {train_accuracy:.2f}% Val Loss: {val_loss:.4f} Val Accu: {val_accuracy:.2f}%")<br>        LOGGER.info(f"Epoch [{epoch+1}/{NUM_EPOCHS}]: Train Loss: {train_loss:.4f} Train Accu: {train_accuracy:.4f} Val Loss: {val_loss:.4f} Val Accu: {val_accuracy:.4f}")<br>torch.save(model.state_dict(),'best_model.pt')</pre> <blockquote>Epoch [1/10]: Train Loss: 1.2264 Train Accu: 66.01% Val Loss: 1.3759 Val Accu: 56.47% <br>Epoch [2/10]: Train Loss: 0.9750 Train Accu: 80.94% Val Loss: 2.1438 Val Accu: 56.47%</blockquote> <h4>Save the Best model, performing the best on Validation dataset</h4> <pre>best_model = SFCN()<br># best_model.load_state_dict('best_model.pt')<br><br>#using the above model for now<br>new_state_dict = {}<br>for key, value in model.state_dict().items():<br>    new_key = key.replace("module.", "")<br>    new_state_dict[new_key] = value<br>best_model.load_state_dict(new_state_dict)</pre> <h4>Test Predictions</h4> <pre>best_model.to(DEVICE)<br>best_model.eval()<br>test_loss = 0.0<br>test_total = 0<br>test_correct = 0<br><br>with torch.no_grad():<br>    all_predicted = []<br>    all_labels = []<br>    for inputs, labels in test_dl:<br>        inputs = inputs.to(DEVICE)<br>        labels = labels.to(DEVICE)<br>        <br>        outputs = best_model(inputs)<br>        te_loss = criterion(outputs, labels)<br>        test_loss += te_loss.item()/inputs.size(0)<br>        probability = torch.sigmoid(outputs)<br>        predicted = (probability &gt;= 0.5).float()<br>        all_predicted.extend(predicted.cpu().numpy().ravel().tolist())<br>        all_labels.extend(labels.cpu().numpy().ravel().tolist())<br>        test_total += labels.size(0)<br>        test_correct += (predicted == labels).sum().item()<br><br>    test_accuracy = 100 * test_correct / test_total<br><br>print(f"TEST LOSS: {test_loss}, TEST ACCURACY: {test_accuracy}")<br>LOGGER.info(f"TEST LOSS: {test_loss}, TEST ACCURACY: {test_accuracy}")<br>accuracy = accuracy_score(all_labels, all_predicted)<br>sensitivity = recall_score(all_labels, all_predicted)<br>print(f'Accuracy: {accuracy}, Sensitivity (Recall): {sensitivity}')<br>LOGGER.info(f'Accuracy: {accuracy}, Sensitivity (Recall): {sensitivity}')<br><br>cm = confusion_matrix(all_labels, all_predicted)<br>print('CM: ',cm)<br>LOGGER.info(f"CM : {cm}")<br>plt.figure(figsize=(8, 6))<br>sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",xticklabels=['Male', 'Female'], yticklabels=['Male', 'Female'])<br>plt.title('Confusion Matrix')<br>plt.xlabel('Predicted')<br>plt.ylabel('True')<br>plt.savefig('cm.png')</pre> <blockquote>TEST LOSS: 42.06333679519594, TEST ACCURACY: 55.62130177514793 Accuracy: 0.5562130177514792, <br>Sensitivity (Recall): 1.0</blockquote> <figure><img alt="" src="https://cdn-images-1.medium.com/max/640/1*tQBxe0QfRrSjSG8PNpE6lg.png"><figcaption>It’s very baddd right !!!, choosing the best model for testing is important !</figcaption></figure> <h4><strong>K-Fold Cross Validation for Training with early stopping</strong></h4> <pre>kf = KFold(n_splits=K_FOLDS, shuffle=True, random_state=NP_SEED)<br>fold_train_losses, fold_val_losses = [], []<br>fold_train_accuracies, fold_val_accuracies = [], []<br>LOGGER.info(f"{K_FOLDS} FOLDS CROSS VALIATION TARINING STARTED")<br><br>for fold, (train_idx, val_idx) in enumerate(kf.split(train_dataset)):<br>    print(f'Fold {fold+1}/{K_FOLDS}')<br>    LOGGER.info(f'Fold {fold+1}/{K_FOLDS}')<br>    <br>    train_ds = Subset(train_dataset, train_idx)<br>    val_ds = Subset(train_dataset, val_idx)<br>    <br>    train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)<br>    val_dl = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)<br><br>    model = SFCN().to(DEVICE)<br>    model = nn.DataParallel(model) <br>    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)<br>    <br>    criterion = nn.BCEWithLogitsLoss()<br><br>    best_val_loss = np.inf<br>    epochs_without_improvement = 0<br><br>    # Train the model for each fold<br>    for epoch in range(NUM_EPOCHS):<br>        model.train()<br>        train_loss = 0.0<br>        train_total = 0<br>        train_correct = 0<br><br>        for inputs, labels in train_dl:<br>            inputs = inputs.to(DEVICE)<br>            labels = labels.to(DEVICE)<br>            optimizer.zero_grad()<br>            outputs = model(inputs)<br>            tloss = criterion(outputs, labels)<br>            tloss.backward()<br>            optimizer.step()<br>            train_loss += tloss.item() / inputs.size(0)<br>            probability = torch.sigmoid(outputs)<br>            predicted = (probability &gt;= 0.5).float()<br>            train_total += labels.size(0)<br>            train_correct += (predicted == labels).sum().item()<br><br>        train_accuracy = 100 * train_correct / train_total<br>        fold_train_accuracies.append(train_accuracy)<br>        fold_train_losses.append(train_loss)<br><br>        model.eval()<br>        val_loss = 0.0<br>        val_total = 0<br>        val_correct = 0<br><br>        with torch.no_grad():<br>            for inputs, labels in val_dl:<br>                inputs = inputs.to(DEVICE)<br>                labels = labels.to(DEVICE)<br>                outputs = model(inputs)<br>                vloss = criterion(outputs, labels)<br>                val_loss += vloss.item() / inputs.size(0)<br>                probability = torch.sigmoid(outputs)<br>                predicted = (probability &gt;= 0.5).float()<br>                val_total += labels.size(0)<br>                val_correct += (predicted == labels).sum().item()<br><br>            val_accuracy = 100 * val_correct / val_total<br>            fold_val_accuracies.append(val_accuracy)<br>            fold_val_losses.append(val_loss)<br><br>            print(f"Fold [{fold+1}/{K_FOLDS}], Epoch [{epoch+1}/{NUM_EPOCHS}]: Train Loss: {train_loss:.4f} Train Accu: {train_accuracy:.2f}% Val Loss: {val_loss:.4f} Val Accu: {val_accuracy:.2f}%")<br>            LOGGER.info(f"Fold [{fold+1}/{K_FOLDS}], Epoch [{epoch+1}/{NUM_EPOCHS}]: Train Loss: {train_loss:.4f} Train Accu: {train_accuracy:.2f}% Val Loss: {val_loss:.4f} Val Accu: {val_accuracy:.2f}%")<br>        <br>        # Early stopping<br>        if epoch &gt; 30:<br>            if val_loss &lt; best_val_loss:<br>                best_val_loss = val_loss<br>                epochs_without_improvement = 0 <br><br>                new_state_dict = {}<br>                for key, value in model.state_dict().items():<br>                    new_key = key.replace("module.", "")<br>                    new_state_dict[new_key] = value<br>                best_model.load_state_dict(new_state_dict)<br><br>                # torch.save(model.state_dict(), f'{RESULT_DIR}/model_{fold+1}_epoch{epoch}.pt') # will create a lot of model and take a lot of space<br>                LOGGER.info(f"Validation loss improved for fold {fold+1} at epoch {epoch+1}")<br>            else:<br>                epochs_without_improvement += 1<br>                LOGGER.info(f"No improvement in validation loss for {epochs_without_improvement} epochs for fold {fold+1}")<br><br>            if epochs_without_improvement &gt;= EARLY_STOPPING_PATIENCE:<br>                print(f"Early stopping triggered for fold {fold+1} at epoch {epoch+1}")<br>                LOGGER.info(f"Early stopping triggered for fold {fold+1} at epoch {epoch+1}")<br>                ## save best model before stopping<br>                torch.save(model.state_dict(), f'{RESULT_DIR}/best_model_{fold+1}_epoch{epoch}.pt')<br>                break<br>    <br>    torch.save(model.state_dict(), f'{RESULT_DIR}/best_model_{fold+1}_epoch{epoch}.pt') ## save model as best model if the training ends for a fold<br><br># Aggregate the results across all folds<br>avg_train_loss = np.mean(fold_train_losses)<br>avg_val_loss = np.mean(fold_val_losses)<br>avg_train_accuracy = np.mean(fold_train_accuracies)<br>avg_val_accuracy = np.mean(fold_val_accuracies)<br><br>print(f"Avg Train Loss: {avg_train_loss:.4f}, Avg Train Accu: {avg_train_accuracy:.2f}%, Avg Val Loss: {avg_val_loss:.4f}, Avg Val Accu: {avg_val_accuracy:.2f}%")<br>LOGGER.info(f"Avg Train Loss: {avg_train_loss:.4f}, Avg Train Accu: {avg_train_accuracy:.2f}%, Avg Val Loss: {avg_val_loss:.4f}, Avg Val Accu: {avg_val_accuracy:.2f}%")</pre> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*mvFbhCMgiEG0-mNbtyLt_w.png"><figcaption>sample output</figcaption></figure> <p>Test with the Best model obtained across the 5 crosses</p> <pre>best_model = SFCN()<br><br>best_model_state_dict = torch.load('path/to/scripts/best_model_2_epoch9.pt', weights_only=True)<br>new_state_dict = {}<br>for key, value in best_model_state_dict.items():<br>    new_key = key.replace("module.", "")<br>    new_state_dict[new_key] = value<br>best_model.load_state_dict(new_state_dict)<br><br>best_model.to(DEVICE)<br>best_model.eval()<br>test_loss = 0.0<br>test_total = 0<br>test_correct = 0<br><br>with torch.no_grad():<br>    all_predicted = []<br>    all_labels = []<br>    for inputs, labels in test_dl:<br>        inputs = inputs.to(DEVICE)<br>        labels = labels.to(DEVICE)<br>        <br>        outputs = best_model(inputs)<br>        te_loss = criterion(outputs, labels)<br>        test_loss += te_loss.item()/inputs.size(0)<br>        probability = torch.sigmoid(outputs)<br>        predicted = (probability &gt;= 0.5).float()<br>        all_predicted.extend(predicted.cpu().numpy().ravel().tolist())<br>        all_labels.extend(labels.cpu().numpy().ravel().tolist())<br>        test_total += labels.size(0)<br>        test_correct += (predicted == labels).sum().item()<br><br>    test_accuracy = 100 * test_correct / test_total<br><br>print(f"TEST LOSS: {test_loss}, TEST ACCURACY: {test_accuracy}")<br>LOGGER.info(f"TEST LOSS: {test_loss}, TEST ACCURACY: {test_accuracy}")<br>accuracy = accuracy_score(all_labels, all_predicted)<br>sensitivity = recall_score(all_labels, all_predicted)<br>print(f'Accuracy: {accuracy}, Sensitivity (Recall): {sensitivity}')<br>LOGGER.info(f'Accuracy: {accuracy}, Sensitivity (Recall): {sensitivity}')<br><br>cm = confusion_matrix(all_labels, all_predicted)<br>print('CM: ',cm)<br>LOGGER.info(f"CM : {cm}")<br>plt.figure(figsize=(8, 6))<br>sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",xticklabels=['Male', 'Female'], yticklabels=['Male', 'Female'])<br>plt.title('Confusion Matrix')<br>plt.xlabel('Predicted')<br>plt.ylabel('True')<br>plt.savefig('cm.png')</pre> <blockquote>TEST LOSS: 14.311684928834438, TEST ACCURACY: 89.94082840236686<br>Accuracy: 0.8994082840236687, Sensitivity (Recall): 0.9354838709677419</blockquote> <figure><img alt="" src="https://cdn-images-1.medium.com/max/640/1*DqZS6_j_nPQSWXJaYlqYoQ.png"></figure> <p>Link to the <a href="https://github.com/blackpearl006/kaggle-notebooks/blob/main/sex_classification.ipynb" rel="external nofollow noopener" target="_blank">Notebook</a></p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=f941c6ef547a" width="1" height="1" alt=""></p> </body></html>