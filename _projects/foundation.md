---
layout: page
title: Foundation Models for LLMs and Neuroimaging
description: In-progress project on building large-scale models for brain and language data
importance: 2
category: work
related_publications: false
status: in progress
---

This project explores building **foundation models** that learn from both **language data** and **neuroimaging**. Inspired by modern LLMs, we're adapting transformer architectures to handle brain MRI data and clinical text for multi-task learning across neuroimaging applications.

We're following resources like:
- [MIT Intro to Deep Learning](https://introtodeeplearning.com/)
- [Stanford CS336](https://stanford-cs336.github.io/)
- [YouTube playlist](https://youtube.com/playlist?list=PLoROMvodv4rOY23Y0BoGoBGgQ1zmU_MT_)

Current focus: pretraining on synthetic brain-text pairs, building small GPT-style models, and testing transfer to brain age and disease tasks.

_Results and code will be released soon._
